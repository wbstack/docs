(window.webpackJsonp=window.webpackJsonp||[]).push([[20],{387:function(e,t,a){"use strict";a.r(t);var s=a(24),o=Object(s.a)({},(function(){var e=this,t=e.$createElement,a=e._self._c||t;return a("ContentSlotsDistributor",{attrs:{"slot-key":e.$parent.slotKey}},[a("h1",{attrs:{id:"one-wdqs-server-vs-a-cluster"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#one-wdqs-server-vs-a-cluster"}},[e._v("#")]),e._v(" One WDQS server vs a cluster")]),e._v(" "),a("div",{staticClass:"custom-block warning"},[a("p",{staticClass:"custom-block-title"},[e._v("WARNING")]),e._v(" "),a("p",[e._v("This decision document has not yet been formatted for nice display...")])]),e._v(" "),a("p",[e._v("Date: 27 August 2019\nDecision: Single service, namespace & prefix adjusted, more complex later.")]),e._v(" "),a("p",[e._v("A single WDQS server can host the whole of wikidata, so size isn't going to be an\nissue starting out.\nNumber of requests should also be fairly low, so no need to worry here yet.\nAlso the complexity of queries should be fairly low as most data sets should be small.")]),e._v(" "),a("p",[e._v("It should be easy to spot growth in this area and easy to adapt to changes.")]),e._v(" "),a("p",[e._v("If the JNL breaks, initially it shouldn't be too hard to reload ALL of the data for\nall of the wikis. And this could be expected in Alpha...")]),e._v(" "),a("p",[e._v("If number of READ queries is too much then we need another copy with the same data set.\nThis can easily be done by:")]),e._v(" "),a("ul",[a("li",[e._v("Dumping the current jnl.")]),e._v(" "),a("li",[e._v("Either by stopping the service, taking a copy, and turning it back on")]),e._v(" "),a("li",[e._v("Or https://wiki.blazegraph.com/wiki/index.php/REST_API#Online_Backup")]),e._v(" "),a("li",[e._v("Alter the current updater to write to both servers and track the status seperalty?")]),e._v(" "),a("li",[e._v("OR have 2 updaters?")]),e._v(" "),a("li",[e._v("PROFIT")])]),e._v(" "),a("p",[e._v("If number of WRITES is too much then we may need to split the namespaces across\nmore than one WDQS instances.\nThis could be done with:")]),e._v(" "),a("ul",[a("li",[e._v("The same steps as above to create 2 copies of the current service.")]),e._v(" "),a("li",[e._v("Destroy the namespaces we don't want on the next shard https://wiki.blazegraph.com/wiki/index.php/REST_API#DESTROY_DATA_SET")]),e._v(" "),a("li",[e._v("Create some load balancer / system that knows where each NS is")]),e._v(" "),a("li",[e._v("Use LB to direct traffic to correct server")]),e._v(" "),a("li",[e._v("Destroy namespaces from the first shard we don't need.\nThis again needs updater changes to write the correct things to the right server.")])]),e._v(" "),a("h3",{attrs:{id:"gateway"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#gateway"}},[e._v("#")]),e._v(" Gateway")]),e._v(" "),a("p",[e._v("The general idea would be to have some sort of gateway (similar to vitess)\nThe gateway knows:")]),e._v(" "),a("ul",[a("li",[e._v("How to map the outer prefix to inner prefixes (wikidata.org -> abc123[dbname]")]),e._v(" "),a("li",[e._v("This allows sites to be re-named without needing to reload all data?")]),e._v(" "),a("li",[e._v("Which internal blazegraph endpoint to forward the request to based on the request")]),e._v(" "),a("li",[e._v("Which internal blazegraph namespace to forward the request to based on the request")])]),e._v(" "),a("p",[e._v("It might be worth giving https://www.blazegraph.com/whitepapers/bigdata_ha_whitepaper.pdf\na read..")]),e._v(" "),a("h3",{attrs:{id:"operator"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#operator"}},[e._v("#")]),e._v(" Operator")]),e._v(" "),a("p",[e._v("Further down the line it would be great to have a k8s operator to do all of this:")]),e._v(" "),a("ul",[a("li",[e._v("Sharding")]),e._v(" "),a("li",[e._v("Scaling")]),e._v(" "),a("li",[e._v("Replication / Updating")]),e._v(" "),a("li",[e._v("Backups")]),e._v(" "),a("li",[e._v("etc.")])])])}),[],!1,null,null,null);t.default=o.exports}}]);